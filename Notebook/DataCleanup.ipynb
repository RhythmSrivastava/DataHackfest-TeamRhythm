{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_package_data.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_package_data.json\"\n",
    "output_csv_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_package_data.csv\"\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, route_data in data.items():\n",
    "        for location_id, location_data in route_data.items():\n",
    "            for package_id, package_data in location_data.items():\n",
    "                # Create a flattened dictionary\n",
    "                flattened_entry = {\n",
    "                    \"RouteID\": route_id,\n",
    "                    \"LocationID\": location_id,\n",
    "                    \"PackageID\": package_id,\n",
    "                    \"StartTimeUTC\": package_data[\"time_window\"].get(\"start_time_utc\"),\n",
    "                    \"EndTimeUTC\": package_data[\"time_window\"].get(\"end_time_utc\"),\n",
    "                    \"PlannedServiceTimeSeconds\": package_data.get(\"planned_service_time_seconds\"),\n",
    "                    \"DepthCM\": package_data[\"dimensions\"].get(\"depth_cm\"),\n",
    "                    \"HeightCM\": package_data[\"dimensions\"].get(\"height_cm\"),\n",
    "                    \"WidthCM\": package_data[\"dimensions\"].get(\"width_cm\")\n",
    "                }\n",
    "                flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_route_data.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_route_data.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, route_data in data.items():\n",
    "        if \"stops\" in route_data:\n",
    "            for stop_id, stop_data in route_data[\"stops\"].items():\n",
    "                # Create a flattened dictionary\n",
    "                flattened_entry = {\n",
    "                    \"RouteID\": route_id,\n",
    "                    \"StationCode\": route_data.get(\"station_code\"),\n",
    "                    \"Date\": route_data.get(\"date_YYYY_MM_DD\"),\n",
    "                    \"DepartureTimeUTC\": route_data.get(\"departure_time_utc\"),\n",
    "                    \"ExecutorCapacityCM3\": route_data.get(\"executor_capacity_cm3\"),\n",
    "                    \"StopID\": stop_id,\n",
    "                    \"Latitude\": stop_data.get(\"lat\"),\n",
    "                    \"Longitude\": stop_data.get(\"lng\"),\n",
    "                    \"Type\": stop_data.get(\"type\"),\n",
    "                    \"ZoneID\": stop_data.get(\"zone_id\")\n",
    "                }\n",
    "                flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_travel_times.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_travel_times.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, locations in data.items():\n",
    "        for loc_start, distances in locations.items():\n",
    "            for loc_end, distance in distances.items():\n",
    "                flattened_entry = {\n",
    "                    \"RouteID\": route_id,\n",
    "                    \"StartLocation\": loc_start,\n",
    "                    \"EndLocation\": loc_end,\n",
    "                    \"Distance\": distance\n",
    "                }\n",
    "                flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\actual_sequences.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\actual_sequences.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, route_data in data.items():\n",
    "        for category, locations in route_data.items():\n",
    "            for loc_id, value in locations.items():\n",
    "                flattened_entry = {\n",
    "                    \"RouteID\": route_id,\n",
    "                    \"Category\": category,\n",
    "                    \"LocationID\": loc_id,\n",
    "                    \"Value\": value\n",
    "                }\n",
    "                flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\invalid_sequence_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\invalid_sequence_scores.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, score in data.items():\n",
    "        flattened_entry = {\n",
    "            \"RouteID\": route_id,\n",
    "            \"Score\": score\n",
    "        }\n",
    "        flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\package_data.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\package_data.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, locations in data.items():\n",
    "        for location_id, packages in locations.items():\n",
    "            for package_id, package_data in packages.items():\n",
    "                # Create a flattened dictionary\n",
    "                flattened_entry = {\n",
    "                    \"RouteID\": route_id,\n",
    "                    \"LocationID\": location_id,\n",
    "                    \"PackageID\": package_id,\n",
    "                    \"ScanStatus\": package_data[\"scan_status\"],\n",
    "                    \"StartTimeUTC\": package_data[\"time_window\"].get(\"start_time_utc\"),\n",
    "                    \"EndTimeUTC\": package_data[\"time_window\"].get(\"end_time_utc\"),\n",
    "                    \"PlannedServiceTimeSeconds\": package_data.get(\"planned_service_time_seconds\"),\n",
    "                    \"DepthCM\": package_data[\"dimensions\"].get(\"depth_cm\"),\n",
    "                    \"HeightCM\": package_data[\"dimensions\"].get(\"height_cm\"),\n",
    "                    \"WidthCM\": package_data[\"dimensions\"].get(\"width_cm\")\n",
    "                }\n",
    "                flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Replace NaN values with None (or appropriate handling)\n",
    "df = df.replace({np.nan: None})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\route_data.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\route_data.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, route_info in data.items():\n",
    "        station_code = route_info.get(\"station_code\")\n",
    "        date = route_info.get(\"date_YYYY_MM_DD\")\n",
    "        departure_time = route_info.get(\"departure_time_utc\")\n",
    "        executor_capacity = route_info.get(\"executor_capacity_cm3\")\n",
    "        route_score = route_info.get(\"route_score\")\n",
    "        stops = route_info.get(\"stops\", {})\n",
    "        for stop_id, stop_info in stops.items():\n",
    "            flattened_entry = {\n",
    "                \"RouteID\": route_id,\n",
    "                \"StationCode\": station_code,\n",
    "                \"Date\": date,\n",
    "                \"DepartureTimeUTC\": departure_time,\n",
    "                \"ExecutorCapacityCM3\": executor_capacity,\n",
    "                \"RouteScore\": route_score,\n",
    "                \"StopID\": stop_id,\n",
    "                \"Latitude\": stop_info.get(\"lat\"),\n",
    "                \"Longitude\": stop_info.get(\"lng\"),\n",
    "                \"Type\": stop_info.get(\"type\"),\n",
    "                \"ZoneID\": stop_info.get(\"zone_id\")\n",
    "            }\n",
    "            flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Replace NaN values with None (or appropriate handling)\n",
    "df = df.replace({np.nan: None})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\travel_times.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\travel_times.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, stops_info in data.items():\n",
    "        for stop_id, stop_data in stops_info.items():\n",
    "            for destination_id, travel_time in stop_data.items():\n",
    "                flattened_entry = {\n",
    "                    \"RouteID\": route_id,\n",
    "                    \"StopID\": stop_id,\n",
    "                    \"DestinationID\": destination_id,\n",
    "                    \"TravelTime\": travel_time\n",
    "                }\n",
    "                flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Replace NaN values with None (or appropriate handling)\n",
    "df = df.replace({np.nan: None})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_score_inputs\\new_actual_sequences.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_score_inputs\\new_actual_sequences.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, route_info in data.items():\n",
    "        actual_times = route_info.get(\"actual\", {})\n",
    "        for location, time in actual_times.items():\n",
    "            flattened_entry = {\n",
    "                \"RouteID\": route_id,\n",
    "                \"Location\": location,\n",
    "                \"ActualTime\": time\n",
    "            }\n",
    "            flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Replace NaN values with None (or appropriate handling)\n",
    "df = df.replace({np.nan: None})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON to CSV and saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_score_inputs\\new_invalid_sequence_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the input JSON file and output CSV file paths\n",
    "input_json_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_score_inputs\\new_invalid_sequence_scores.json\"\n",
    "output_csv_path = os.path.splitext(input_json_path)[0] + '.csv'\n",
    "\n",
    "# Function to flatten the JSON structure\n",
    "def flatten_json(data):\n",
    "    flattened_data = []\n",
    "    for route_id, time_value in data.items():\n",
    "        flattened_entry = {\n",
    "            \"RouteID\": route_id,\n",
    "            \"TimeValue\": time_value\n",
    "        }\n",
    "        flattened_data.append(flattened_entry)\n",
    "    return flattened_data\n",
    "\n",
    "# Read the JSON file\n",
    "with open(input_json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten the JSON data\n",
    "flattened_data = flatten_json(json_data)\n",
    "\n",
    "# Convert the flattened data to a pandas DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Replace NaN values with None (or appropriate handling)\n",
    "df = df.replace({np.nan: None})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Converted JSON to CSV and saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: new_package_data.csv\n",
      "No primary keys found\n",
      "-----------------------------------------\n",
      "File: new_route_data.csv\n",
      "No primary keys found\n",
      "-----------------------------------------\n",
      "File: new_travel_times.csv\n",
      "No primary keys found\n",
      "-----------------------------------------\n",
      "Completed primary key identification for all CSV files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\"\n",
    "\n",
    "# Function to determine primary keys in a DataFrame\n",
    "def find_primary_keys(df):\n",
    "    primary_keys = []\n",
    "    for col in df.columns:\n",
    "        if df[col].is_unique:\n",
    "            primary_keys.append(col)\n",
    "    return primary_keys\n",
    "\n",
    "# Iterate through all CSV files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        primary_keys = find_primary_keys(df)\n",
    "        print(f\"File: {filename}\")\n",
    "        if primary_keys:\n",
    "            print(f\"Primary Keys: {', '.join(primary_keys)}\")\n",
    "        else:\n",
    "            print(\"No primary keys found\")\n",
    "        print(\"-\" + \"-\"*40)\n",
    "\n",
    "print(\"Completed primary key identification for all CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for primary keys / column names\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\"\n",
    "\n",
    "# Function to get column names of a DataFrame\n",
    "def get_column_names(df):\n",
    "    return df.columns.tolist()\n",
    "\n",
    "# Iterate through all CSV files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        column_names = get_column_names(df)\n",
    "        print(f\"File: {filename}\")\n",
    "        print(f\"Column Names: {', '.join(column_names)}\")\n",
    "        print(\"-\" + \"-\"*40)\n",
    "\n",
    "print(\"Completed column name extraction for all CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3129 entries, 0 to 3128\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   RouteID                    3129 non-null   object \n",
      " 1   LocationID                 3127 non-null   object \n",
      " 2   PackageID                  3129 non-null   object \n",
      " 3   StartTimeUTC               210 non-null    object \n",
      " 4   EndTimeUTC                 210 non-null    object \n",
      " 5   PlannedServiceTimeSeconds  3129 non-null   float64\n",
      " 6   DepthCM                    3129 non-null   float64\n",
      " 7   HeightCM                   3129 non-null   float64\n",
      " 8   WidthCM                    3129 non-null   float64\n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 220.1+ KB\n",
      "None\n",
      "                                        RouteID LocationID  \\\n",
      "0  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AH   \n",
      "1  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AK   \n",
      "2  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AN   \n",
      "3  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AU   \n",
      "4  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AV   \n",
      "\n",
      "                                        PackageID StartTimeUTC EndTimeUTC  \\\n",
      "0  PackageID_07017709-2ddd-4c6a-8b7e-ebde70a4f0fa          NaN        NaN   \n",
      "1  PackageID_30d78e0b-3dfd-4123-a392-a187ee55c789          NaN        NaN   \n",
      "2  PackageID_31472e01-c4ac-4281-b9ae-281a152f0d53          NaN        NaN   \n",
      "3  PackageID_180d6ed8-e08c-4a2a-972c-b0d6f1bd68ed          NaN        NaN   \n",
      "4  PackageID_9b96689a-99ef-4fc3-9281-ad7442c746ec          NaN        NaN   \n",
      "\n",
      "   PlannedServiceTimeSeconds  DepthCM  HeightCM  WidthCM  \n",
      "0                       78.0     36.1       7.1     20.8  \n",
      "1                      157.0     28.2       4.8     25.7  \n",
      "2                       60.0     27.4       5.6     24.9  \n",
      "3                       33.0     30.5       2.5     27.9  \n",
      "4                       47.0     30.5       3.8     22.9  \n",
      "\n",
      "Route Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2051 entries, 0 to 2050\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   RouteID              2051 non-null   object \n",
      " 1   StationCode          2051 non-null   object \n",
      " 2   Date                 2051 non-null   object \n",
      " 3   DepartureTimeUTC     2051 non-null   object \n",
      " 4   ExecutorCapacityCM3  2051 non-null   float64\n",
      " 5   StopID               2049 non-null   object \n",
      " 6   Latitude             2051 non-null   float64\n",
      " 7   Longitude            2051 non-null   float64\n",
      " 8   Type                 2051 non-null   object \n",
      " 9   ZoneID               2022 non-null   object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 160.4+ KB\n",
      "None\n",
      "                                        RouteID StationCode        Date  \\\n",
      "0  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
      "1  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
      "2  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
      "3  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
      "4  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
      "\n",
      "  DepartureTimeUTC  ExecutorCapacityCM3 StopID   Latitude  Longitude     Type  \\\n",
      "0         15:12:44            4247527.0     AH  42.129085 -88.027485  Dropoff   \n",
      "1         15:12:44            4247527.0     AK  42.133454 -88.043144  Dropoff   \n",
      "2         15:12:44            4247527.0     AN  42.129422 -88.037895  Dropoff   \n",
      "3         15:12:44            4247527.0     AU  42.107882 -88.035445  Dropoff   \n",
      "4         15:12:44            4247527.0     AV  42.138752 -88.041745  Dropoff   \n",
      "\n",
      "   ZoneID  \n",
      "0  D-8.3E  \n",
      "1  D-8.2H  \n",
      "2  D-8.2H  \n",
      "3  D-8.1C  \n",
      "4  D-7.1J  \n",
      "\n",
      "Travel Times Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 330793 entries, 0 to 330792\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   RouteID        330793 non-null  object \n",
      " 1   StartLocation  330488 non-null  object \n",
      " 2   EndLocation    330488 non-null  object \n",
      " 3   Distance       330793 non-null  float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 10.1+ MB\n",
      "None\n",
      "                                        RouteID StartLocation EndLocation  \\\n",
      "0  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AH   \n",
      "1  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AK   \n",
      "2  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AN   \n",
      "3  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AU   \n",
      "4  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AV   \n",
      "\n",
      "   Distance  \n",
      "0       0.0  \n",
      "1     287.4  \n",
      "2     249.4  \n",
      "3     476.9  \n",
      "4     421.2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "package_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_package_data.csv\"\n",
    "route_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_route_data.csv\"\n",
    "travel_times_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_travel_times.csv\"\n",
    "\n",
    "# Load each CSV file into a DataFrame\n",
    "package_data_df = pd.read_csv(package_data_path)\n",
    "route_data_df = pd.read_csv(route_data_path)\n",
    "travel_times_data_df = pd.read_csv(travel_times_data_path)\n",
    "\n",
    "# Display basic information about each DataFrame\n",
    "print(\"Package Data:\")\n",
    "print(package_data_df.info())\n",
    "print(package_data_df.head())\n",
    "\n",
    "print(\"\\nRoute Data:\")\n",
    "print(route_data_df.info())\n",
    "print(route_data_df.head())\n",
    "\n",
    "print(\"\\nTravel Times Data:\")\n",
    "print(travel_times_data_df.info())\n",
    "print(travel_times_data_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RouteID</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>PackageID</th>\n",
       "      <th>StartTimeUTC</th>\n",
       "      <th>EndTimeUTC</th>\n",
       "      <th>PlannedServiceTimeSeconds</th>\n",
       "      <th>DepthCM</th>\n",
       "      <th>HeightCM</th>\n",
       "      <th>WidthCM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AH</td>\n",
       "      <td>PackageID_07017709-2ddd-4c6a-8b7e-ebde70a4f0fa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AK</td>\n",
       "      <td>PackageID_30d78e0b-3dfd-4123-a392-a187ee55c789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AN</td>\n",
       "      <td>PackageID_31472e01-c4ac-4281-b9ae-281a152f0d53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AU</td>\n",
       "      <td>PackageID_180d6ed8-e08c-4a2a-972c-b0d6f1bd68ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AV</td>\n",
       "      <td>PackageID_9b96689a-99ef-4fc3-9281-ad7442c746ec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        RouteID LocationID  \\\n",
       "0  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AH   \n",
       "1  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AK   \n",
       "2  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AN   \n",
       "3  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AU   \n",
       "4  RouteID_15baae2d-bf07-4967-956a-173d4036613f         AV   \n",
       "\n",
       "                                        PackageID StartTimeUTC EndTimeUTC  \\\n",
       "0  PackageID_07017709-2ddd-4c6a-8b7e-ebde70a4f0fa          NaN        NaN   \n",
       "1  PackageID_30d78e0b-3dfd-4123-a392-a187ee55c789          NaN        NaN   \n",
       "2  PackageID_31472e01-c4ac-4281-b9ae-281a152f0d53          NaN        NaN   \n",
       "3  PackageID_180d6ed8-e08c-4a2a-972c-b0d6f1bd68ed          NaN        NaN   \n",
       "4  PackageID_9b96689a-99ef-4fc3-9281-ad7442c746ec          NaN        NaN   \n",
       "\n",
       "   PlannedServiceTimeSeconds  DepthCM  HeightCM  WidthCM  \n",
       "0                       78.0     36.1       7.1     20.8  \n",
       "1                      157.0     28.2       4.8     25.7  \n",
       "2                       60.0     27.4       5.6     24.9  \n",
       "3                       33.0     30.5       2.5     27.9  \n",
       "4                       47.0     30.5       3.8     22.9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RouteID</th>\n",
       "      <th>StationCode</th>\n",
       "      <th>Date</th>\n",
       "      <th>DepartureTimeUTC</th>\n",
       "      <th>ExecutorCapacityCM3</th>\n",
       "      <th>StopID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>ZoneID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>DCH4</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>15:12:44</td>\n",
       "      <td>4247527.0</td>\n",
       "      <td>AH</td>\n",
       "      <td>42.129085</td>\n",
       "      <td>-88.027485</td>\n",
       "      <td>Dropoff</td>\n",
       "      <td>D-8.3E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>DCH4</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>15:12:44</td>\n",
       "      <td>4247527.0</td>\n",
       "      <td>AK</td>\n",
       "      <td>42.133454</td>\n",
       "      <td>-88.043144</td>\n",
       "      <td>Dropoff</td>\n",
       "      <td>D-8.2H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>DCH4</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>15:12:44</td>\n",
       "      <td>4247527.0</td>\n",
       "      <td>AN</td>\n",
       "      <td>42.129422</td>\n",
       "      <td>-88.037895</td>\n",
       "      <td>Dropoff</td>\n",
       "      <td>D-8.2H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>DCH4</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>15:12:44</td>\n",
       "      <td>4247527.0</td>\n",
       "      <td>AU</td>\n",
       "      <td>42.107882</td>\n",
       "      <td>-88.035445</td>\n",
       "      <td>Dropoff</td>\n",
       "      <td>D-8.1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>DCH4</td>\n",
       "      <td>2018-08-11</td>\n",
       "      <td>15:12:44</td>\n",
       "      <td>4247527.0</td>\n",
       "      <td>AV</td>\n",
       "      <td>42.138752</td>\n",
       "      <td>-88.041745</td>\n",
       "      <td>Dropoff</td>\n",
       "      <td>D-7.1J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        RouteID StationCode        Date  \\\n",
       "0  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
       "1  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
       "2  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
       "3  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
       "4  RouteID_15baae2d-bf07-4967-956a-173d4036613f        DCH4  2018-08-11   \n",
       "\n",
       "  DepartureTimeUTC  ExecutorCapacityCM3 StopID   Latitude  Longitude     Type  \\\n",
       "0         15:12:44            4247527.0     AH  42.129085 -88.027485  Dropoff   \n",
       "1         15:12:44            4247527.0     AK  42.133454 -88.043144  Dropoff   \n",
       "2         15:12:44            4247527.0     AN  42.129422 -88.037895  Dropoff   \n",
       "3         15:12:44            4247527.0     AU  42.107882 -88.035445  Dropoff   \n",
       "4         15:12:44            4247527.0     AV  42.138752 -88.041745  Dropoff   \n",
       "\n",
       "   ZoneID  \n",
       "0  D-8.3E  \n",
       "1  D-8.2H  \n",
       "2  D-8.2H  \n",
       "3  D-8.1C  \n",
       "4  D-7.1J  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RouteID</th>\n",
       "      <th>StartLocation</th>\n",
       "      <th>EndLocation</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AH</td>\n",
       "      <td>AH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AH</td>\n",
       "      <td>AK</td>\n",
       "      <td>287.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AH</td>\n",
       "      <td>AN</td>\n",
       "      <td>249.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AH</td>\n",
       "      <td>AU</td>\n",
       "      <td>476.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RouteID_15baae2d-bf07-4967-956a-173d4036613f</td>\n",
       "      <td>AH</td>\n",
       "      <td>AV</td>\n",
       "      <td>421.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        RouteID StartLocation EndLocation  \\\n",
       "0  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AH   \n",
       "1  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AK   \n",
       "2  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AN   \n",
       "3  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AU   \n",
       "4  RouteID_15baae2d-bf07-4967-956a-173d4036613f            AH          AV   \n",
       "\n",
       "   Distance  \n",
       "0       0.0  \n",
       "1     287.4  \n",
       "2     249.4  \n",
       "3     476.9  \n",
       "4     421.2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_times_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13676739 entries, 0 to 13676738\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   RouteID                    object \n",
      " 1   LocationID                 object \n",
      " 2   PackageID                  object \n",
      " 3   StartTimeUTC               object \n",
      " 4   EndTimeUTC                 object \n",
      " 5   PlannedServiceTimeSeconds  float64\n",
      " 6   DepthCM                    float64\n",
      " 7   HeightCM                   float64\n",
      " 8   WidthCM                    float64\n",
      " 9   StationCode                object \n",
      " 10  Date                       object \n",
      " 11  DepartureTimeUTC           object \n",
      " 12  ExecutorCapacityCM3        float64\n",
      " 13  StopID                     object \n",
      " 14  Latitude                   float64\n",
      " 15  Longitude                  float64\n",
      " 16  Type                       object \n",
      " 17  ZoneID                     object \n",
      " 18  StartLocation              object \n",
      " 19  EndLocation                object \n",
      " 20  Distance                   float64\n",
      "dtypes: float64(8), object(13)\n",
      "memory usage: 2.2+ GB\n",
      "None\n",
      "                                        RouteID LocationID  \\\n",
      "0  RouteID_fffd257c-3041-4736-be7a-5efea8af1173         XV   \n",
      "1  RouteID_fffd257c-3041-4736-be7a-5efea8af1173         XV   \n",
      "2  RouteID_fffd257c-3041-4736-be7a-5efea8af1173         XV   \n",
      "3  RouteID_fffd257c-3041-4736-be7a-5efea8af1173         XV   \n",
      "4  RouteID_fffd257c-3041-4736-be7a-5efea8af1173         XV   \n",
      "\n",
      "                                        PackageID StartTimeUTC EndTimeUTC  \\\n",
      "0  PackageID_7408be25-cdba-4c9e-99e1-a93f4f80f9db          NaN        NaN   \n",
      "1  PackageID_7408be25-cdba-4c9e-99e1-a93f4f80f9db          NaN        NaN   \n",
      "2  PackageID_7408be25-cdba-4c9e-99e1-a93f4f80f9db          NaN        NaN   \n",
      "3  PackageID_7408be25-cdba-4c9e-99e1-a93f4f80f9db          NaN        NaN   \n",
      "4  PackageID_7408be25-cdba-4c9e-99e1-a93f4f80f9db          NaN        NaN   \n",
      "\n",
      "   PlannedServiceTimeSeconds  DepthCM  HeightCM  WidthCM StationCode  ...  \\\n",
      "0                       54.0     31.8       1.3     29.2        DCH4  ...   \n",
      "1                       54.0     31.8       1.3     29.2        DCH4  ...   \n",
      "2                       54.0     31.8       1.3     29.2        DCH4  ...   \n",
      "3                       54.0     31.8       1.3     29.2        DCH4  ...   \n",
      "4                       54.0     31.8       1.3     29.2        DCH4  ...   \n",
      "\n",
      "  DepartureTimeUTC ExecutorCapacityCM3  StopID   Latitude  Longitude     Type  \\\n",
      "0         15:23:57           4247527.0      LS  42.198477 -88.362395  Dropoff   \n",
      "1         15:23:57           4247527.0      LS  42.198477 -88.362395  Dropoff   \n",
      "2         15:23:57           4247527.0      LS  42.198477 -88.362395  Dropoff   \n",
      "3         15:23:57           4247527.0      LS  42.198477 -88.362395  Dropoff   \n",
      "4         15:23:57           4247527.0      LS  42.198477 -88.362395  Dropoff   \n",
      "\n",
      "    ZoneID StartLocation EndLocation Distance  \n",
      "0  B-29.3D            FV          TK    383.9  \n",
      "1  B-29.3D            RO          XA    262.9  \n",
      "2  B-29.3D            CY          SA    258.2  \n",
      "3  B-29.3D            KD          AL    131.2  \n",
      "4  B-29.3D            OB          CV    532.3  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Master DataFrame saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\master_data_sampled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "package_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_package_data.csv\"\n",
    "route_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_route_data.csv\"\n",
    "travel_times_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_travel_times.csv\"\n",
    "\n",
    "# Load each CSV file into a DataFrame\n",
    "package_data_df = pd.read_csv(package_data_path)\n",
    "route_data_df = pd.read_csv(route_data_path)\n",
    "travel_times_data_df = pd.read_csv(travel_times_data_path)\n",
    "\n",
    "# Sample each DataFrame\n",
    "package_data_sampled = package_data_df.sample(frac=0.1, random_state=1)  # Adjust fraction as needed\n",
    "route_data_sampled = route_data_df.sample(frac=0.1, random_state=1)  # Adjust fraction as needed\n",
    "travel_times_data_sampled = travel_times_data_df.sample(frac=0.1, random_state=1)  # Adjust fraction as needed\n",
    "\n",
    "# Perform full outer join on the sampled DataFrames using RouteID as the key\n",
    "master_df = pd.merge(package_data_sampled, route_data_sampled, on='RouteID', how='outer')\n",
    "master_df = pd.merge(master_df, travel_times_data_sampled, on='RouteID', how='outer')\n",
    "\n",
    "# Display basic information about the master DataFrame\n",
    "print(\"Master DataFrame:\")\n",
    "print(master_df.info())\n",
    "print(master_df.head())\n",
    "\n",
    "# Save the master DataFrame to a CSV file (optional)\n",
    "master_df_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\master_data_sampled.csv\"\n",
    "master_df.to_csv(master_df_path, index=False)\n",
    "print(f\"Master DataFrame saved to {master_df_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Master DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 232926 entries, 11084569 to 11057747\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   RouteID                    232926 non-null  object \n",
      " 1   LocationID                 232115 non-null  object \n",
      " 2   PackageID                  232926 non-null  object \n",
      " 3   StartTimeUTC               11699 non-null   object \n",
      " 4   EndTimeUTC                 11699 non-null   object \n",
      " 5   PlannedServiceTimeSeconds  232926 non-null  float64\n",
      " 6   DepthCM                    232926 non-null  float64\n",
      " 7   HeightCM                   232926 non-null  float64\n",
      " 8   WidthCM                    232926 non-null  float64\n",
      " 9   StationCode                232926 non-null  object \n",
      " 10  Date                       232926 non-null  object \n",
      " 11  DepartureTimeUTC           232926 non-null  object \n",
      " 12  ExecutorCapacityCM3        232926 non-null  float64\n",
      " 13  StopID                     231987 non-null  object \n",
      " 14  Latitude                   232926 non-null  float64\n",
      " 15  Longitude                  232926 non-null  float64\n",
      " 16  Type                       232926 non-null  object \n",
      " 17  ZoneID                     229119 non-null  object \n",
      " 18  StartLocation              232705 non-null  object \n",
      " 19  EndLocation                232731 non-null  object \n",
      " 20  Distance                   232926 non-null  float64\n",
      "dtypes: float64(8), object(13)\n",
      "memory usage: 39.1+ MB\n",
      "None\n",
      "                                               RouteID LocationID  \\\n",
      "11084569  RouteID_d1a8c3dd-fa67-455c-a68d-af2fd6aa5d91         SH   \n",
      "12392087  RouteID_693060a6-88bb-4324-9e9c-925d5240263c         JX   \n",
      "11821856  RouteID_693060a6-88bb-4324-9e9c-925d5240263c         TY   \n",
      "12848290  RouteID_693060a6-88bb-4324-9e9c-925d5240263c         SW   \n",
      "7269049   RouteID_2b8df66d-fcd4-438e-931c-3b84b36a5c6b         XI   \n",
      "\n",
      "                                               PackageID StartTimeUTC  \\\n",
      "11084569  PackageID_0c661976-ccc5-4e86-a3fb-6dd7a8b5e006          NaN   \n",
      "12392087  PackageID_cf74cd00-ec9e-462f-aa54-f44468b5925b          NaN   \n",
      "11821856  PackageID_c6c33e57-64e0-45dd-af90-8ce55f9c317a          NaN   \n",
      "12848290  PackageID_19076759-c006-4f75-9cda-d5d0f0a530b1          NaN   \n",
      "7269049   PackageID_78300566-e594-4c9c-91a5-6f91dd36b443          NaN   \n",
      "\n",
      "         EndTimeUTC  PlannedServiceTimeSeconds  DepthCM  HeightCM  WidthCM  \\\n",
      "11084569        NaN                      128.0     25.4      12.7     17.8   \n",
      "12392087        NaN                       80.0     24.9       8.1     22.4   \n",
      "11821856        NaN                       67.5     30.2       5.3     17.5   \n",
      "12848290        NaN                      127.5     40.6      12.7     30.5   \n",
      "7269049         NaN                       31.0     27.6      18.2     19.2   \n",
      "\n",
      "         StationCode  ... DepartureTimeUTC ExecutorCapacityCM3  StopID  \\\n",
      "11084569        DBO2  ...         13:14:21           3313071.0      IQ   \n",
      "12392087        DSE5  ...         14:14:04           3313071.0      AH   \n",
      "11821856        DSE5  ...         14:14:04           3313071.0      CP   \n",
      "12848290        DSE5  ...         14:14:04           3313071.0      VS   \n",
      "7269049         DLA9  ...         14:37:26           4247527.0      BZ   \n",
      "\n",
      "           Latitude   Longitude     Type   ZoneID StartLocation EndLocation  \\\n",
      "11084569  42.292367  -71.165866  Dropoff  B-29.3D            OQ          DB   \n",
      "12392087  47.507399 -122.341610  Dropoff   B-6.3B            QW          SE   \n",
      "11821856  47.512169 -122.375075  Dropoff   B-7.3B            PL          BF   \n",
      "12848290  47.506752 -122.357807  Dropoff   B-6.1A            UQ          PI   \n",
      "7269049   33.659252 -117.675343  Dropoff   G-4.1D            ST          IF   \n",
      "\n",
      "         Distance  \n",
      "11084569    428.2  \n",
      "12392087    340.1  \n",
      "11821856    355.7  \n",
      "12848290    269.1  \n",
      "7269049     277.6  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Final Master DataFrame saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\final_master_data_sampled.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "package_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_package_data.csv\"\n",
    "route_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_route_data.csv\"\n",
    "travel_times_data_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\new_travel_times.csv\"\n",
    "\n",
    "# Load each CSV file into a DataFrame\n",
    "package_data_df = pd.read_csv(package_data_path)\n",
    "route_data_df = pd.read_csv(route_data_path)\n",
    "travel_times_data_df = pd.read_csv(travel_times_data_path)\n",
    "\n",
    "# Sample each DataFrame\n",
    "package_data_sampled = package_data_df.sample(frac=0.1, random_state=1)  # Adjust fraction as needed\n",
    "route_data_sampled = route_data_df.sample(frac=0.1, random_state=1)  # Adjust fraction as needed\n",
    "travel_times_data_sampled = travel_times_data_df.sample(frac=0.1, random_state=1)  # Adjust fraction as needed\n",
    "\n",
    "# Perform full outer join on the sampled DataFrames using RouteID as the key\n",
    "master_df = pd.merge(package_data_sampled, route_data_sampled, on='RouteID', how='outer')\n",
    "master_df = pd.merge(master_df, travel_times_data_sampled, on='RouteID', how='outer')\n",
    "\n",
    "# Estimate the fraction needed to reduce the master DataFrame to ~200 MB\n",
    "approx_size_per_row = master_df.memory_usage(deep=True).sum() / len(master_df)\n",
    "target_size = 200 * 1024 * 1024  # 200 MB in bytes\n",
    "desired_row_count = target_size / approx_size_per_row\n",
    "sampling_fraction = desired_row_count / len(master_df)\n",
    "\n",
    "# Sample the master DataFrame to reduce its size\n",
    "final_master_df = master_df.sample(frac=sampling_fraction, random_state=1)\n",
    "\n",
    "# Display basic information about the final master DataFrame\n",
    "print(\"Final Master DataFrame:\")\n",
    "print(final_master_df.info())\n",
    "print(final_master_df.head())\n",
    "\n",
    "# Save the final master DataFrame to a CSV file\n",
    "final_master_df_path = r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_apply_inputs\\final_master_data_sampled.csv\"\n",
    "final_master_df.to_csv(final_master_df_path, index=False)\n",
    "print(f\"Final Master DataFrame saved to {final_master_df_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 232926 entries, 11084569 to 11057747\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   RouteID                    232926 non-null  object \n",
      " 1   LocationID                 232115 non-null  object \n",
      " 2   PackageID                  232926 non-null  object \n",
      " 3   StartTimeUTC               11699 non-null   object \n",
      " 4   EndTimeUTC                 11699 non-null   object \n",
      " 5   PlannedServiceTimeSeconds  232926 non-null  float64\n",
      " 6   DepthCM                    232926 non-null  float64\n",
      " 7   HeightCM                   232926 non-null  float64\n",
      " 8   WidthCM                    232926 non-null  float64\n",
      " 9   StationCode                232926 non-null  object \n",
      " 10  Date                       232926 non-null  object \n",
      " 11  DepartureTimeUTC           232926 non-null  object \n",
      " 12  ExecutorCapacityCM3        232926 non-null  float64\n",
      " 13  StopID                     231987 non-null  object \n",
      " 14  Latitude                   232926 non-null  float64\n",
      " 15  Longitude                  232926 non-null  float64\n",
      " 16  Type                       232926 non-null  object \n",
      " 17  ZoneID                     229119 non-null  object \n",
      " 18  StartLocation              232705 non-null  object \n",
      " 19  EndLocation                232731 non-null  object \n",
      " 20  Distance                   232926 non-null  float64\n",
      "dtypes: float64(8), object(13)\n",
      "memory usage: 39.1+ MB\n"
     ]
    }
   ],
   "source": [
    "final_master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited DataFrame 'actual_sequences_limited' saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\actual_sequences_limited.csv and retained in memory.\n",
      "Limited DataFrame 'invalid_sequence_scores_limited' saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\invalid_sequence_scores_limited.csv and retained in memory.\n",
      "Limited DataFrame 'package_data_limited' saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\package_data_limited.csv and retained in memory.\n",
      "Limited DataFrame 'route_data_limited' saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\route_data_limited.csv and retained in memory.\n",
      "Limited DataFrame 'travel_times_limited' saved to C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\travel_times_limited.csv and retained in memory.\n",
      "DataFrames are now available in memory with static names for further use.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file paths (placeholders for up to 5 CSV files)\n",
    "csv_file_paths = [\n",
    "    r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\actual_sequences.csv\",\n",
    "    r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\invalid_sequence_scores.csv\",\n",
    "    r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\package_data.csv\",\n",
    "    r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\route_data.csv\",\n",
    "    r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\\Dataset\\almrrc2021_data\\almrrc2021-data-training\\model_build_inputs\\travel_times.csv\"\n",
    "]\n",
    "\n",
    "# Function to read and limit CSV file to approximately 20 MB\n",
    "def read_and_limit_csv(file_path, target_size_mb=20):\n",
    "    target_size_bytes = target_size_mb * 1024 * 1024\n",
    "    chunk = pd.read_csv(file_path, nrows=1000)  # Read a small chunk to estimate memory usage per row\n",
    "    row_size = chunk.memory_usage(deep=True).sum() / len(chunk)\n",
    "    num_rows_to_read = int(target_size_bytes / row_size)\n",
    "    \n",
    "    df = pd.read_csv(file_path, nrows=num_rows_to_read)\n",
    "    return df\n",
    "\n",
    "# Dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Read and limit each CSV file, save to individual files, and keep them in memory with static names\n",
    "for file_path in csv_file_paths:\n",
    "    limited_df = read_and_limit_csv(file_path, target_size_mb=20)\n",
    "    df_name = os.path.splitext(os.path.basename(file_path))[0] + '_limited'\n",
    "    dataframes[df_name] = limited_df\n",
    "    output_path = file_path.replace('.csv', '_limited.csv')\n",
    "    limited_df.to_csv(output_path, index=False)\n",
    "    print(f\"Limited DataFrame '{df_name}' saved to {output_path} and retained in memory.\")\n",
    "\n",
    "# Assign the DataFrames to static variable names for direct use\n",
    "actual_sequences_limited = dataframes['actual_sequences_limited']\n",
    "invalid_sequence_scores_limited = dataframes['invalid_sequence_scores_limited']\n",
    "package_data_limited = dataframes['package_data_limited']\n",
    "route_data_limited = dataframes['route_data_limited']\n",
    "travel_times_limited = dataframes['travel_times_limited']\n",
    "\n",
    "print(\"DataFrames are now available in memory with static names for further use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory: C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\")\n",
    "print(\"Changed working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_model_apply_inputs = pd.read_csv(r\"Dataset/almrrc2021_data/almrrc2021-data-training/Cleaned Data/model_apply_inputs/final_master_data_sampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\mailg\n",
      "Changed working directory: C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(r\"C:\\Users\\mailg\\OneDrive\\Documents\\GitHub\\DataHackfest-TeamRhythm\")\n",
    "print(\"Changed working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
